// =====================================
// SISTEMA DE INTELIGENCIA ARTIFICIAL PARA SEMILLEROS DEITANA
// =====================================
// 
// Este archivo es el n√∫cleo central del asistente IA empresarial que:
// - Procesa consultas naturales y las convierte en SQL
// - Integra conocimiento empresarial con datos actuales
// - Proporciona respuestas personalizadas y naturales
// - Mantiene contexto conversacional y memoria
// - Soporta streaming en tiempo real
//
// ARQUITECTURA PRINCIPAL:
// 1. An√°lisis de intenci√≥n con IA
// 2. Construcci√≥n inteligente de prompts
// 3. Ejecuci√≥n de SQL con validaci√≥n
// 4. Formateo natural de respuestas
// 5. Persistencia en Firestore y Pinecone
// 6. Streaming en tiempo real
//
// AUTOR: Sistema de IA Semilleros Deitana
// VERSI√ìN: 2.0 (Optimizada con una sola llamada IA)
// FECHA: 2024
// =====================================

// =====================================
// IMPORTACIONES Y CONFIGURACI√ìN INICIAL
// =====================================

const { OpenAI } = require('openai');
const pool = require('../../db');
const chatManager = require('../../utils/chatManager');
const admin = require('../../firebase-admin');
const pineconeMemoria = require('../../utils/pinecone');
const comandosMemoria = require('../../utils/comandosMemoria');
const langfuseUtils = require('../../utils/langfuse');
require('dotenv').config();
const mapaERP = require('./mapaERP');
// Importaciones desde las carpetas organizadas
const {
    formatoObligatorio, 
    formatoRespuesta,
    formatoRespuestaSimple,
    formatoUltraNatural,
    guiaMarkdownCompleta,
    estiloVisualChatGPT,
    prioridadMaximaChatGPT,
    promptGlobal, 
    promptBase, 
    comportamientoGlobal,
    comportamientoChatGPT
} = require('../prompts/GLOBAL');

const { sqlRules } = require('../prompts/SQL');

const { identidadEmpresa, terminologia } = require('../prompts/DEITANA');

// Importar sistema RAG
const ragInteligente = require('../data/integrar_rag_nuevo');
const { analizarIntencionConIA } = require('../data/funcion_intencion_ia');

// Inicializar el cliente de OpenAI
const openai = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY
});

// =====================================
// CONFIGURACI√ìN DE VARIABLES GLOBALES
// =====================================

// Historial global de conversaci√≥n (en memoria, para demo)
const conversationHistory = [];
// Contexto de datos reales de la √∫ltima consulta relevante
let lastRealData = null;

// =====================================
// FUNCIONES AUXILIARES - FORMATEO Y UTILIDADES
// =====================================
// 
// Estas funciones se encargan de:
// - Formatear resultados SQL en Markdown
// - Obtener descripciones de columnas desde mapaERP
// - Determinar tablas basadas en columnas
// - Limitar y aleatorizar resultados
// - Generar respuestas naturales y conversacionales
// =====================================



/**
 * Funci√≥n para formatear la respuesta final - RESPUESTAS NATURALES
 * Convierte resultados SQL en respuestas conversacionales y amigables
 * 
 * @param {Array} results - Resultados de la consulta SQL
 * @param {string} query - Consulta original del usuario
 * @returns {string} Respuesta formateada de forma natural
 * 
 * CARACTER√çSTICAS:
 * - Detecta tipo de entidad (clientes, t√©cnicos, etc.)
 * - Genera saludos personalizados
 * - Filtra resultados v√°lidos
 * - Capitaliza nombres autom√°ticamente
 * - Agrega preguntas de seguimiento
 */


// =====================================
// FUNCIONES DE EJECUCI√ìN Y VALIDACI√ìN SQL
// =====================================
// 
// Estas funciones manejan:
// - Ejecuci√≥n segura de consultas SQL
// - Validaci√≥n y extracci√≥n de SQL de respuestas de IA
// - Reemplazo de nombres de tablas con nombres reales
// - Validaci√≥n de tablas y columnas en mapaERP
// - Prevenci√≥n de SQL injection
// - Correcci√≥n autom√°tica de sintaxis SQL
// =====================================

/**
 * Funci√≥n para ejecutar consultas SQL con manejo de errores
 * @param {string} sql - Consulta SQL a ejecutar
 * @returns {Promise<Array>} Resultados de la consulta
 */
async function executeQuery(sql) {
    try {
        // Reemplazar los nombres de las tablas con sus nombres reales
        const sqlModificado = reemplazarNombresTablas(sql);
        console.log('üîç [SQL-EXEC] Ejecutando:', sqlModificado);
        const [rows] = await pool.query(sqlModificado);
        console.log('üìä [SQL-RESULT] Filas devueltas:', rows.length);
        
        if (rows.length === 0) {
            console.log('‚ö†Ô∏è [SQL-RESULT] La consulta no devolvi√≥ resultados');
            return [];
        }

        return rows;
    } catch (error) {
        console.error('‚ùå [SQL-EXEC] Error ejecutando consulta:', error.message);
        console.error('‚ùå [SQL-EXEC] SQL:', sql);
        throw error;
    }
}

/**
 * Funci√≥n para validar que la respuesta contiene una consulta SQL v√°lida
 * Extrae SQL de diferentes formatos y valida su sintaxis
 * 
 * @param {string} response - Respuesta de OpenAI
 * @returns {string|null} SQL validado o null si no es v√°lido
 * 
 * FORMATOS SOPORTADOS:
 * - <sql>SELECT...</sql>
 * - ```sql SELECT...```
 * - SELECT... (texto plano)
 */
function validarRespuestaSQL(response) {
    console.log('üîç [SQL-VALIDATION] Validando respuesta para extraer SQL...');
    
    const sqlQueries = [];
    
    // Buscar m√∫ltiples consultas SQL con etiquetas <sql>
    const sqlMatches = response.match(/<sql>([\s\S]*?)<\/sql>/g);
    if (sqlMatches) {
        console.log('‚úÖ [SQL-VALIDATION] Encontradas', sqlMatches.length, 'consultas SQL con etiquetas');
        sqlMatches.forEach((match, index) => {
            const sqlContent = match.replace(/<\/?sql>/g, '').trim();
            if (sqlContent && sqlContent.toLowerCase().startsWith('select')) {
                sqlQueries.push(procesarSQL(sqlContent, `SQL ${index + 1}`));
            }
        });
    }
    
    // Si no encontr√≥ con etiquetas, buscar con bloques de c√≥digo SQL
    if (sqlQueries.length === 0) {
        const codeMatches = response.match(/```sql\s*([\s\S]*?)```/g);
        if (codeMatches) {
            console.log('‚úÖ [SQL-VALIDATION] Encontradas', codeMatches.length, 'consultas SQL en bloques de c√≥digo');
            codeMatches.forEach((match, index) => {
                const sqlContent = match.replace(/```sql\s*/, '').replace(/```/, '').trim();
                if (sqlContent && sqlContent.toLowerCase().startsWith('select')) {
                    sqlQueries.push(procesarSQL(sqlContent, `SQL ${index + 1}`));
                }
            });
        }
    }
    
    // Si no encontr√≥ con bloques, buscar SQL en texto plano
    if (sqlQueries.length === 0) {
        console.log('üîç [SQL-VALIDATION] Buscando SQL en texto plano...');
        const sqlPattern = /(SELECT\s+[\s\S]*?)(?:;|$)/gi;
        let match;
        let index = 0;
        while ((match = sqlPattern.exec(response)) !== null) {
            const sqlContent = match[1].trim();
            if (sqlContent && sqlContent.toLowerCase().startsWith('select')) {
                sqlQueries.push(procesarSQL(sqlContent, `SQL ${index + 1}`));
                index++;
            }
        }
        if (sqlQueries.length > 0) {
            console.log('‚úÖ [SQL-VALIDATION] Encontradas', sqlQueries.length, 'consultas SQL en texto plano');
        }
    }
    
    if (sqlQueries.length === 0) {
        console.log('‚ùå [SQL-VALIDATION] No se encontr√≥ SQL en la respuesta');
        return null;
    }
    
    // Si solo hay una consulta, devolverla como string (compatibilidad)
    if (sqlQueries.length === 1) {
        return sqlQueries[0];
    }
    
    // Si hay m√∫ltiples consultas, devolver array
    console.log('‚úÖ [SQL-VALIDATION] Devolviendo', sqlQueries.length, 'consultas SQL');
    return sqlQueries;
}

function procesarSQL(sql, nombre) {
    console.log(`üîç [SQL-PROCESSING] Procesando ${nombre}:`, sql.substring(0, 100) + '...');
    
    // Validar que es una consulta SQL v√°lida
    if (!sql.toLowerCase().startsWith('select')) {
        console.error(`‚ùå [SQL-PROCESSING] ${nombre} no es SELECT`);
        throw new Error(`${nombre} debe comenzar con SELECT`);
    }
    
    // Validar y corregir sintaxis com√∫n
    if (sql.includes('OFFSET')) {
        const offsetMatch = sql.match(/LIMIT\s+(\d+)\s+OFFSET\s+(\d+)/i);
        if (offsetMatch) {
            sql = sql.replace(
                /LIMIT\s+(\d+)\s+OFFSET\s+(\d+)/i,
                `LIMIT ${offsetMatch[2]}, ${offsetMatch[1]}`
            );
            console.log(`üîÑ [SQL-PROCESSING] Corregida sintaxis OFFSET en ${nombre}`);
        }
    }
    
    // Verificar si es una consulta de conteo
    const esConsultaConteo = sql.toLowerCase().includes('count(*)');
    const tieneDistinct = /select\s+distinct/i.test(sql);
    const tieneGroupBy = /group by/i.test(sql);
    const tieneJoin = /join/i.test(sql);
    const tieneFiltroFecha = /where[\s\S]*fpe_fec|where[\s\S]*fecha|where[\s\S]*_fec/i.test(sql);
    
    // Si no tiene LIMIT y no es excepci√≥n, AGREGAR LIMIT autom√°ticamente
    if (!esConsultaConteo && !tieneDistinct && !tieneGroupBy && !sql.toLowerCase().includes('limit') && !(tieneJoin && tieneFiltroFecha)) {
        sql = sql.replace(/;*\s*$/, '');
        sql += ' LIMIT 10';
        console.log(`üîÑ [SQL-PROCESSING] Agregado LIMIT autom√°tico en ${nombre}`);
    }
    
    console.log(`‚úÖ [SQL-PROCESSING] ${nombre} validado:`, sql.substring(0, 100) + '...');
    return sql;
}



// Funci√≥n para reemplazar nombres de tablas en la consulta SQL
function reemplazarNombresTablas(sql) {
    let sqlModificado = sql;
    Object.keys(mapaERP).forEach(key => {
        if (mapaERP[key].tabla && mapaERP[key].tabla.includes('-')) {
            const regex = new RegExp(`\\b${key}\\b`, 'g');
            sqlModificado = sqlModificado.replace(regex, `\`${mapaERP[key].tabla}\``);
        }
    });
    return sqlModificado;
}

// Funci√≥n para validar que la tabla existe en mapaERP






// =====================================
// FUNCIONES DE PERSISTENCIA Y ALMACENAMIENTO
// =====================================
// 
// Estas funciones gestionan:
// - Guardado de mensajes de usuario en Firestore
// - Guardado de respuestas del asistente
// - Detecci√≥n de preguntas de seguimiento
// - Organizaci√≥n de conversaciones por usuario
// - Persistencia as√≠ncrona para no bloquear respuestas
// =====================================

// Funci√≥n auxiliar para detectar si la pregunta es de seguimiento sobre tel√©fono de cliente


// Funci√≥n para guardar mensaje en Firestore
async function saveMessageToFirestore(userId, message, isAdmin = true) {
    try {
        const now = new Date();
        const messageData = {
            content: message,
            role: 'user',
            timestamp: now
        };

        const userChatRef = chatManager.chatsCollection.doc(userId);
        const conversationRef = userChatRef.collection('conversations').doc('admin_conversation');
        
        // Primero obtenemos el documento actual
        const conversationDoc = await conversationRef.get();
        let messages = [];
        
        if (conversationDoc.exists) {
            messages = conversationDoc.data().messages || [];
        }
        
        // Agregamos el nuevo mensaje
        messages.push(messageData);
        
        // Actualizamos el documento con el nuevo array de mensajes
        await conversationRef.set({
            lastUpdated: now,
            messages: messages
        }, { merge: true });

        return true;
    } catch (error) {
        console.error('Error al guardar mensaje en Firestore:', error);
        return false;
    }
}

// Funci√≥n para guardar mensaje del asistente en Firestore
async function saveAssistantMessageToFirestore(userId, message) {
    try {
        const now = new Date();
        const messageData = {
            content: message,
            role: 'assistant',
            timestamp: now
        };

        const userChatRef = chatManager.chatsCollection.doc(userId);
        const conversationRef = userChatRef.collection('conversations').doc('admin_conversation');
        
        // Primero obtenemos el documento actual
        const conversationDoc = await conversationRef.get();
        let messages = [];
        
        if (conversationDoc.exists) {
            messages = conversationDoc.data().messages || [];
        }
        
        // Agregamos el nuevo mensaje
        messages.push(messageData);
        
        // LIMITAR EL TAMA√ëO DE LA CONVERSACI√ìN PARA EVITAR ERRORES DE FIRESTORE
        const MAX_MESSAGES = 30; // M√°ximo 30 mensajes por conversaci√≥n
        const MAX_MESSAGE_SIZE = 50000; // M√°ximo 50KB por mensaje
        
        // Si el mensaje es muy grande, truncarlo
        if (messageData.content.length > MAX_MESSAGE_SIZE) {
            console.log(`‚ö†Ô∏è [FIRESTORE] Mensaje muy grande (${messageData.content.length} chars), truncando...`);
            messageData.content = messageData.content.substring(0, MAX_MESSAGE_SIZE) + '\n\n[Contenido truncado por l√≠mite de tama√±o]';
        }
        
        // Si hay demasiados mensajes, mantener solo los √∫ltimos MAX_MESSAGES
        if (messages.length > MAX_MESSAGES) {
            console.log(`‚ö†Ô∏è [FIRESTORE] Demasiados mensajes (${messages.length}), manteniendo √∫ltimos ${MAX_MESSAGES}...`);
            messages = messages.slice(-MAX_MESSAGES);
        }
        
        // Calcular tama√±o aproximado del documento
        const documentSize = JSON.stringify({
            lastUpdated: now,
            messages: messages
        }).length;
        
        if (documentSize > 900000) { // 900KB como margen de seguridad
            console.log(`‚ö†Ô∏è [FIRESTORE] Documento muy grande (${documentSize} bytes), limpiando conversaci√≥n...`);
            // Mantener solo los √∫ltimos 10 mensajes
            messages = messages.slice(-10);
        }
        
        // Actualizamos el documento con el nuevo array de mensajes
        await conversationRef.set({
            lastUpdated: now,
            messages: messages
        }, { merge: true });

        console.log(`‚úÖ [FIRESTORE] Mensaje guardado. Total mensajes: ${messages.length}`);
        return true;
    } catch (error) {
        console.error('Error al guardar mensaje del asistente en Firestore:', error);
        
        // Si el error es por tama√±o, intentar limpiar la conversaci√≥n
        if (error.message && error.message.includes('exceeds the maximum allowed size')) {
            console.log('üîÑ [FIRESTORE] Intentando limpiar conversaci√≥n por tama√±o...');
            try {
                const userChatRef = chatManager.chatsCollection.doc(userId);
                const conversationRef = userChatRef.collection('conversations').doc('admin_conversation');
                
                // Crear nueva conversaci√≥n con solo el mensaje actual
                await conversationRef.set({
                    lastUpdated: new Date(),
                    messages: [{
                        content: message.length > 50000 ? message.substring(0, 50000) + '\n\n[Contenido truncado]' : message,
                        role: 'assistant',
                        timestamp: new Date()
                    }]
                });
                
                console.log('‚úÖ [FIRESTORE] Conversaci√≥n limpiada exitosamente');
                return true;
            } catch (cleanupError) {
                console.error('‚ùå [FIRESTORE] Error limpiando conversaci√≥n:', cleanupError);
                return false;
            }
        }
        
        return false;
    }
}

// =====================================
// B√öSQUEDA FLEXIBLE (FUZZY SEARCH)
// =====================================
// 
// Esta funci√≥n implementa b√∫squeda inteligente cuando SQL falla:
// - Genera variantes del t√©rmino de b√∫squeda
// - Prueba m√∫ltiples columnas y tablas
// - B√∫squeda multi-t√©rmino para art√≠culos
// - Manejo especial para tablas espec√≠ficas
// - Recuperaci√≥n autom√°tica cuando consultas exactas fallan
// =====================================


// =====================================
// L√ìGICA DE CONSTRUCCI√ìN DE PROMPT INTELIGENTE
// =====================================
// 
// Esta secci√≥n contiene la l√≥gica unificada que antes estaba en construirPrompt.js:
// - An√°lisis de intenci√≥n con IA (SQL, conversaci√≥n, RAG+SQL)
// - Detecci√≥n autom√°tica de tablas relevantes
// - Construcci√≥n de contexto de mapaERP selectivo
// - Modelo √∫nico optimizado (gpt-4o)
// - Construcci√≥n de instrucciones naturales
// - Ensamblaje final del prompt optimizado
// =====================================
// Las importaciones ya est√°n hechas arriba desde las carpetas organizadas

/**
 * Construye un prompt optimizado usando IA inteligente (UNA SOLA LLAMADA)
 * Esta es la funci√≥n principal que orquesta todo el proceso de construcci√≥n
 * 
 * @param {string} mensaje - Consulta del usuario
 * @param {Object} mapaERP - Mapa de estructura de la base de datos
 * @param {Object} openaiClient - Cliente de OpenAI
 * @param {string} contextoPinecone - Contexto de memoria vectorial
 * @param {string} contextoDatos - Datos de contexto previo
 * @param {boolean} modoDesarrollo - Modo de desarrollo para debugging
 * @returns {Object} Prompt construido con configuraci√≥n y m√©tricas
 */
async function construirPromptInteligente(mensaje, mapaERP, openaiClient, contextoPinecone = '', contextoDatos = '', historialConversacion = [], modoDesarrollo = false) {
    console.log('üöÄ [PROMPT-BUILDER] Construyendo prompt ULTRA-OPTIMIZADO...');
    
    // 1. AN√ÅLISIS INTELIGENTE R√ÅPIDO (SIN LLAMADAS IA)
    const intencion = await analizarIntencionInteligente(mensaje);
    console.log('üéØ [PROMPT-BUILDER] Intenci√≥n detectada:', intencion);
    
    // 2. Seleccionar modelo apropiado
    const configModelo = seleccionarModeloInteligente(intencion, []);
    
    // 3. SIEMPRE incluir mapaERP - la IA decide si lo usa
    const contextoMapaERP = construirContextoMapaERPCompleto(mapaERP);
    console.log('üìã [MAPA-ERP] Incluyendo mapaERP completo - IA decide si lo usa');
    
    // 4. Construir instrucciones naturales
    const instruccionesNaturales = construirInstruccionesNaturales(intencion, [], contextoPinecone);
    
    // 5. RAG INTELIGENTE Y SELECTIVO (OPTIMIZADO)
    let contextoRAG = '';
    
    // RAG SIEMPRE ACTIVO para evitar alucinaciones
    try {
        console.log('üß† [RAG] Recuperando conocimiento empresarial...');
        contextoRAG = await ragInteligente.recuperarConocimientoRelevante(mensaje, 'sistema');
        console.log('‚úÖ [RAG] Conocimiento recuperado:', contextoRAG ? contextoRAG.length : 0, 'caracteres');
    } catch (error) {
        console.error('‚ùå [RAG] Error recuperando conocimiento:', error.message);
        // Continuar sin RAG si hay error, pero registrar el problema
    }
    
    // 6. Ensamblar prompt final (OPTIMIZADO)
    const fechaActual = new Date().toLocaleString('es-ES', { timeZone: 'Europe/Madrid', dateStyle: 'full', timeStyle: 'short' });
    const promptGlobalConFecha = promptGlobal.replace('{{FECHA_ACTUAL}}', fechaActual);
    let promptFinal = `${promptGlobalConFecha}\n` + instruccionesNaturales;
    
    // Priorizar contexto RAG al inicio del prompt si existe
    if (contextoRAG) {
        console.log('üéØ [RAG] PRIORIZANDO contexto empresarial al inicio');
        promptFinal = `${promptGlobalConFecha}\n\nCONOCIMIENTO EMPRESARIAL ESPEC√çFICO:\n${contextoRAG}\n\nINSTRUCCI√ìN: Debes usar siempre la informaci√≥n del conocimiento empresarial espec√≠fico proporcionado arriba. Si la informaci√≥n est√° disponible en ese contexto, √∫sala. No des respuestas gen√©ricas cuando tengas informaci√≥n espec√≠fica de la empresa.\n\n` + instruccionesNaturales;
    }
    
    // A√±adir estructura de datos SIEMPRE - la IA decide si la usa
    promptFinal += `${contextoMapaERP}\n\n`;
    
    // A√±adir reglas SQL solo para consultas SQL
    if (intencion.tipo === 'sql' || intencion.tipo === 'rag_sql') {
        promptFinal += `${sqlRules}\n\n`;
    }
    
    // El contexto RAG ya se a√±adi√≥ al inicio si existe
    
    // A√±adir contexto de datos previos si existe
    if (contextoDatos) {
        promptFinal += `DATOS DE CONTEXTO PREVIO:\n${contextoDatos}\n\n`;
    }
    
    // A√±adir contexto conversacional de forma inteligente
    if (historialConversacion && historialConversacion.length > 0) {
        const ultimosMensajes = historialConversacion.slice(-4);
        const contextoConversacional = ultimosMensajes.map(msg => 
            `${msg.role === 'user' ? 'Usuario' : 'Asistente'}: ${msg.content}`
        ).join('\n');
        
        promptFinal += `## üí¨ CONTEXTO CONVERSACIONAL RECIENTE\n\n${contextoConversacional}\n\n## üéØ INSTRUCCIONES DE CONTINUIDAD\n\n- Mant√©n la continuidad natural de la conversaci√≥n\n- NO te presentes de nuevo si ya has saludado\n- Usa el contexto previo para dar respuestas coherentes\n- Si el usuario hace referencia a algo mencionado antes, √∫salo\n- Mant√©n el tono y estilo de la conversaci√≥n en curso\n\n`;
    }
    
    console.log('‚úÖ [PROMPT-BUILDER] Prompt construido - MapaERP: SIEMPRE, RAG: SIEMPRE');
    
    return {
        prompt: promptFinal,
        configModelo: configModelo,
        intencion: intencion,
        tablasRelevantes: [], // IA analiza todas las tablas del mapaERP
        metricas: {
            usaIA: true, // IA analiza mapaERP completo
            tablasDetectadas: Object.keys(mapaERP).length,
            llamadasIA: 1, // ¬°Solo UNA llamada!
            optimizado: true,
            modeloUnico: 'gpt-4o',
            mapaERPIncluido: true, // SIEMPRE incluido
            ragIncluido: true // SIEMPRE incluido para evitar alucinaciones
        }
    };
}

/**
 * Analiza la intenci√≥n usando IA real (escalable para 900 tablas y 200 usuarios)
 */
async function analizarIntencionInteligente(mensaje) {
    console.log('üß† [INTENCION-IA] Analizando consulta con IA real...');
    
    try {
        // Usar IA para analizar la intenci√≥n de forma inteligente
        const promptAnalisis = `Analiza la siguiente consulta y determina qu√© tipo de respuesta necesita:

CONSULTA: "${mensaje}"

OPCIONES:
1. "sql" - Si la consulta pide datos, n√∫meros, conteos, listas, informaci√≥n de la base de datos
2. "conocimiento" - Si la consulta pide explicaciones, definiciones, protocolos, informaci√≥n del archivo .txt
3. "conversacion" - Si es un saludo, agradecimiento, o conversaci√≥n casual

Ejemplos:
- "cuantas partidas se hicieron" ‚Üí sql
- "5 t√©cnicos" ‚Üí sql
- "dime 3 vendedores" ‚Üí sql
- "casas comerciales" ‚Üí sql
- "lista de clientes" ‚Üí sql
- "qu√© significa tratamientos extraordinarios" ‚Üí conocimiento  
- "hola, c√≥mo est√°s" ‚Üí conversacion
- "explica el protocolo de germinaci√≥n" ‚Üí conocimiento

Responde SOLO con: sql, conocimiento, o conversacion`;

        const response = await openai.chat.completions.create({
            model: 'gpt-4o-mini',
            messages: [{ role: 'user', content: promptAnalisis }],
            max_tokens: 10,
            temperature: 0.1
        });

        const tipo = response.choices[0].message.content.trim().toLowerCase();
        console.log(`‚úÖ [INTENCION-IA] Tipo detectado: ${tipo}`);

        // Mapear a tipos internos
        if (tipo === 'sql') {
            return { tipo: 'sql', confianza: 0.95 };
        } else if (tipo === 'conocimiento') {
            return { tipo: 'rag_sql', confianza: 0.95 };
        } else {
            return { tipo: 'conversacion', confianza: 0.95 };
        }
        
    } catch (error) {
        console.error('‚ùå [INTENCION-IA] Error:', error.message);
        // Fallback inteligente: si tiene signo de interrogaci√≥n, probablemente necesita datos
        if (mensaje.toLowerCase().includes('?')) {
            return { tipo: 'sql', confianza: 0.7 };
        }
        return { tipo: 'conversacion', confianza: 0.5 };
    }
}





// =====================================
// FUNCIONES DE USUARIO Y CONTEXTO CONVERSACIONAL
// =====================================
// 
// Estas funciones gestionan:
// - Obtenci√≥n de informaci√≥n del usuario desde Firebase
// - Recuperaci√≥n de historial conversacional
// - Personalizaci√≥n de respuestas con nombre del usuario
// - Contexto conversacional para continuidad
// - Gesti√≥n de sesiones y conversaciones
// =====================================

// =====================================
// FUNCI√ìN PRINCIPAL - MODELO GPT Y PROCESAMIENTO
// Se encarga de coordinar todo el proceso de la consulta
// =====================================

// =====================================
// FUNCI√ìN PARA OBTENER INFORMACI√ìN DEL USUARIO
// =====================================

/**
 * Obtiene la informaci√≥n del usuario desde Firebase incluyendo su displayName
 */
async function obtenerInfoUsuario(userId) {
    try {
        console.log('üë§ [USER-INFO] Obteniendo informaci√≥n del usuario:', userId);
        
        const userRecord = await admin.auth().getUser(userId);
        
        const infoUsuario = {
            uid: userRecord.uid,
            nombre: userRecord.displayName || 'Usuario',
            email: userRecord.email,
            esAdmin: userRecord.customClaims?.isAdmin || false
        };
        
        console.log('‚úÖ [USER-INFO] Informaci√≥n obtenida:', {
            nombre: infoUsuario.nombre,
            email: infoUsuario.email?.substring(0, 3) + '***',
            esAdmin: infoUsuario.esAdmin
        });
        
        return infoUsuario;
    } catch (error) {
        console.error('‚ùå [USER-INFO] Error obteniendo informaci√≥n del usuario:', error.message);
        return {
            uid: userId,
            nombre: 'Usuario',
            email: null,
            esAdmin: false
        };
    }
}

// =====================================
// FUNCI√ìN PARA OBTENER HISTORIAL CONVERSACIONAL
// =====================================

/**
 * Obtiene el historial completo de la conversaci√≥n para contexto
 */
async function obtenerHistorialConversacion(userId, conversationId) {
    try {
        console.log('üìú [HISTORIAL] Obteniendo contexto conversacional...');
        console.log('üìú [HISTORIAL] Usuario:', userId, 'Conversaci√≥n:', conversationId);
        
        if (!conversationId || conversationId.startsWith('temp_')) {
            console.log('üìú [HISTORIAL] Conversaci√≥n temporal/nueva - sin historial previo');
            return [];
        }
        
        const mensajes = await chatManager.getConversationMessages(userId, conversationId);
        
        // Solo tomar los √∫ltimos 6 mensajes para contexto (3 intercambios)
        const mensajesRecientes = mensajes.slice(-6);
        
        console.log(`üìú [HISTORIAL] Obtenidos ${mensajesRecientes.length} mensajes para contexto`);
        
        // Formatear para usar en el prompt
        const contextoFormateado = mensajesRecientes.map(msg => ({
            role: msg.role,
            content: msg.content
        }));
        
        return contextoFormateado;
    } catch (error) {
        console.error('‚ùå [HISTORIAL] Error obteniendo historial:', error.message);
        return [];
    }
}

// =====================================
// FUNCI√ìN PARA PERSONALIZAR RESPUESTA CON NOMBRE
// =====================================

/**
 * Personaliza la respuesta incluyendo el nombre del usuario de forma sutil
 */
function personalizarRespuesta(respuesta, nombreUsuario) {
    // No personalizar si es un nombre gen√©rico
    if (!nombreUsuario || nombreUsuario === 'Usuario' || nombreUsuario.length < 2) {
        return respuesta;
    }
    
    console.log(`üé® [PERSONALIZACI√ìN] Personalizando respuesta para ${nombreUsuario}`);
    
    // Patrones para agregar el nombre de forma sutil (no siempre, aproximadamente 30% de las veces)
    const deberiaPersonalizar = Math.random() < 0.3;
    
    if (!deberiaPersonalizar) {
        console.log('üé® [PERSONALIZACI√ìN] Saltando personalizaci√≥n para esta respuesta');
        return respuesta;
    }
    
    const patronesPersonalizacion = [
        // Al inicio de la respuesta
        {
            patron: /^¬°?Hola[!,]?\s*/i,
            reemplazo: `¬°Hola, ${nombreUsuario}! `
        },
        {
            patron: /^Perfecto[!,]?\s*/i,
            reemplazo: `Perfecto, ${nombreUsuario}. `
        },
        // En medio de la respuesta
        {
            patron: /¬øTe sirve esta informaci√≥n\?/i,
            reemplazo: `¬øTe sirve esta informaci√≥n, ${nombreUsuario}?`
        },
        {
            patron: /¬øNecesitas algo m√°s\?/i,
            reemplazo: `¬øNecesitas algo m√°s, ${nombreUsuario}?`
        },
        // Al final de la respuesta
        {
            patron: /¬øEn qu√© m√°s puedo ayudarte\?/i,
            reemplazo: `¬øEn qu√© m√°s puedo ayudarte, ${nombreUsuario}?`
        }
    ];
    
    // Aplicar un patr√≥n aleatorio que coincida
    for (const { patron, reemplazo } of patronesPersonalizacion) {
        if (patron.test(respuesta)) {
            const respuestaPersonalizada = respuesta.replace(patron, reemplazo);
            console.log('‚úÖ [PERSONALIZACI√ìN] Respuesta personalizada aplicada');
            return respuestaPersonalizada;
        }
    }
    
    // Si no coincide ning√∫n patr√≥n, agregar el nombre al final de forma sutil
    if (respuesta.endsWith('?')) {
        return respuesta.slice(0, -1) + `, ${nombreUsuario}?`;
    } else if (respuesta.endsWith('.')) {
        return respuesta.slice(0, -1) + `, ${nombreUsuario}.`;
    }
    
    console.log('üé® [PERSONALIZACI√ìN] No se aplic√≥ personalizaci√≥n espec√≠fica');
    return respuesta;
}

// =====================================
// FUNCI√ìN PRINCIPAL - PROCESAMIENTO DE CONSULTAS
// =====================================
// 
// Esta es la funci√≥n central que coordina todo el proceso:
// - An√°lisis de intenci√≥n y construcci√≥n de prompt
// - Llamada √∫nica optimizada a OpenAI
// - Procesamiento por tipo (SQL, conversaci√≥n, RAG+SQL)
// - Ejecuci√≥n de SQL con validaci√≥n
// - Formateo natural de respuestas
// - Personalizaci√≥n y persistencia
// - Manejo de errores y fallbacks
// =====================================



// =====================================
// FUNCI√ìN STREAMING PARA TIEMPO REAL
// =====================================
// 
// Esta funci√≥n proporciona respuesta en tiempo real:
// - Streaming chunk por chunk al frontend
// - Procesamiento post-streaming para SQL
// - Segunda llamada para explicaci√≥n natural
// - Headers especiales para streaming HTTP
// - Manejo de errores en tiempo real
// - Persistencia as√≠ncrona de respuestas
// =====================================

/**
 * Funci√≥n de streaming para procesamiento en tiempo real
 * Proporciona respuesta chunk por chunk al frontend
 * 
 * @param {Object} params - Par√°metros de la consulta
 * @param {string} params.message - Mensaje del usuario
 * @param {string} params.userId - ID del usuario
 * @param {string} params.conversationId - ID de la conversaci√≥n
 * @param {Object} params.response - Objeto de respuesta HTTP
 * @returns {Object} Resultado del procesamiento
 * 
 * CARACTER√çSTICAS:
 * - Streaming en tiempo real chunk por chunk
 * - Procesamiento post-streaming para SQL
 * - Segunda llamada para explicaci√≥n natural
 * - Headers especiales para streaming HTTP
 * - Manejo de errores en tiempo real
 * - Persistencia as√≠ncrona de respuestas
 */
async function processQueryStream({ message, userId, conversationId, response }) {
    const tiempoInicio = Date.now();
    console.log('üöÄ [STREAMING] ===== INICIANDO PROCESO DE CONSULTA CON STREAMING =====');
    console.log('üöÄ [STREAMING] Procesando consulta:', message);
    console.log('üöÄ [STREAMING] Usuario ID:', userId);
    console.log('üöÄ [STREAMING] Conversaci√≥n ID:', conversationId);

    // =====================================
    // OBTENER INFORMACI√ìN DEL USUARIO Y CONTEXTO
    // =====================================
    
    const infoUsuario = await obtenerInfoUsuario(userId);
    const historialConversacion = await obtenerHistorialConversacion(userId, conversationId);

    try {
        // No esperar a que termine de guardar - hacer async
        saveMessageToFirestore(userId, message).catch(err => 
            console.error('‚ùå [FIRESTORE] Error guardando mensaje:', err.message)
        );
        console.log('üíæ [FIRESTORE] Guardando mensaje del usuario (async)...');

        // =====================================
        // OBTENER CONTEXTO DE MEMORIA (SOLO CUANDO ES NECESARIO)
        // =====================================
        
        console.log('üß† [MEMORIA] Analizando si necesita contexto conversacional...');
        let contextoPinecone = '';
        
        // Detecci√≥n ultra-r√°pida para consultas que necesitan memoria
        const consultasQueNecesitanMemoria = /\b(anterior|antes|mencionaste|dijiste|conversaci√≥n|conversacion|hablamos|recordar|recuerdas|me|mi|entonces|y|bueno|ok|si|s√≠|contin√∫a|continua|m√°s|mas|otros|otra|que|qu√©)\b/i;
        const esRespuestaCorta = message.trim().length < 15;
        const necesitaContexto = consultasQueNecesitanMemoria.test(message) || esRespuestaCorta || historialConversacion.length > 0;
        
        if (necesitaContexto) {
            console.log('üß† [MEMORIA] Consulta requiere contexto - buscando en memoria...');
            
            // Agregar contexto conversacional al contexto de memoria
            if (historialConversacion.length > 0) {
                const ultimosMensajes = historialConversacion.slice(-2); // Solo los 2 √∫ltimos
                const contextoConversacional = ultimosMensajes.map(msg => 
                    `${msg.role === 'user' ? 'Usuario' : 'Asistente'}: ${msg.content}`
                ).join('\n');
                
                contextoPinecone += `\n=== CONTEXTO CONVERSACIONAL RECIENTE ===\n${contextoConversacional}\n\nINSTRUCCI√ìN: Mant√©n la continuidad de la conversaci√≥n anterior.`;
            }
            
            // B√∫squeda de memoria as√≠ncrona (no bloquear la respuesta)
            pineconeMemoria.agregarContextoMemoria(userId, message)
                .then(memoriaAdicional => {
                if (memoriaAdicional) {
                        console.log('‚úÖ [PINECONE] Memoria adicional encontrada (async)');
                    }
                })
                .catch(error => {
                    console.error('‚ùå [PINECONE] Error buscando recuerdos (async):', error.message);
                });
        } else {
            console.log('‚ö° [OPTIMIZACI√ìN] Consulta simple - saltando b√∫squeda de memoria');
        }

        // =====================================
        // CONSTRUIR PROMPT OPTIMIZADO (SIN LLAMADAS IA)
        // =====================================
        
        console.log('üß† [IA-INTELIGENTE] Construyendo prompt OPTIMIZADO...');
        const promptBuilder = await construirPromptInteligente(
            message, 
            mapaERP,
            openai,
            contextoPinecone, 
            lastRealData || '',
            false
        );
        
        console.log('üß† [IA-INTELIGENTE] M√©tricas de construcci√≥n:');
        console.log('üß† [IA-INTELIGENTE] Intenci√≥n detectada:', promptBuilder.intencion);
        console.log('üß† [IA-INTELIGENTE] Modelo seleccionado:', promptBuilder.configModelo.modelo);

        // =====================================
        // CONFIGURAR MENSAJES PARA STREAMING
        // =====================================

        // Construir array de mensajes con historial conversacional
        const mensajesLlamada = [
            {
                role: 'system',
                content: promptBuilder.prompt
            }
        ];

        // Agregar historial conversacional como mensajes reales
        if (historialConversacion && historialConversacion.length > 0) {
            console.log('üí¨ [STREAMING-CONTEXTO] Agregando historial conversacional como mensajes reales...');
            historialConversacion.forEach((msg, index) => {
                console.log(`üí¨ [STREAMING-CONTEXTO] Mensaje ${index + 1}: ${msg.role} - "${msg.content.substring(0, 100)}..."`);
                mensajesLlamada.push({
                    role: msg.role,
                    content: msg.content
                });
            });
        }

        // Agregar el mensaje actual del usuario
        mensajesLlamada.push({
            role: 'user', 
            content: message
        });

        console.log('üìä [STREAMING] Iniciando llamada con stream a OpenAI...');
        console.log('ü§ñ [MODELO-DIN√ÅMICO] Usando modelo:', promptBuilder.configModelo.modelo);

        // =====================================
        // LLAMADA CON STREAMING
        // =====================================

        // Configurar headers para streaming
        response.writeHead(200, {
            'Content-Type': 'text/plain; charset=utf-8',
            'Transfer-Encoding': 'chunked',
            'Access-Control-Allow-Origin': '*',
            'Access-Control-Allow-Headers': 'Content-Type',
            'Cache-Control': 'no-cache',
            'Connection': 'keep-alive'
        });

        let fullResponse = '';
        let tokenCount = 0;
        let sqlDetected = false;

        try {
            const stream = await openai.chat.completions.create({
                model: promptBuilder.configModelo.modelo,
                messages: mensajesLlamada,
                max_tokens: promptBuilder.configModelo.maxTokens,
                temperature: promptBuilder.configModelo.temperature,
                top_p: promptBuilder.configModelo.topP,                       // ‚ö° SAMPLING CREATIVO
                frequency_penalty: promptBuilder.configModelo.frequencyPenalty, // ‚ö° ANTI-REPETICI√ìN
                presence_penalty: promptBuilder.configModelo.presencePenalty,   // ‚ö° DIVERSIDAD
                stream: true  // ¬°AQU√ç EST√Å LA MAGIA!
            });

            console.log('‚úÖ [STREAMING] Stream iniciado correctamente');

            // Procesar cada chunk del stream
            for await (const chunk of stream) {
                const content = chunk.choices[0]?.delta?.content;
                
                if (content) {
                    fullResponse += content;
                    tokenCount++;
                    
                    // Detectar si hay SQL en la respuesta acumulada
                    if (!sqlDetected && fullResponse.includes('<sql>')) {
                        sqlDetected = true;
                        console.log('üîç [STREAMING] SQL detectado en respuesta');
                        
                        // Enviar mensaje de "pensando" en lugar del contenido con SQL
                        response.write(JSON.stringify({
                            type: 'thinking',
                            message: 'Buscando informaci√≥n en el ERP',
                            timestamp: Date.now()
                        }) + '\n');
                    }
                    
                    // Solo enviar chunks si NO se detect√≥ SQL
                    if (!sqlDetected) {
                        response.write(JSON.stringify({
                            type: 'chunk',
                            content: content,
                            timestamp: Date.now()
                        }) + '\n');
                    }
                }
                
                // Si el stream termin√≥
                if (chunk.choices[0]?.finish_reason) {
                    console.log('‚úÖ [STREAMING] Stream completado');
                    break;
                }
            }

            // =====================================
            // PROCESAMIENTO POST-STREAMING
            // =====================================

            console.log('üîç [STREAMING] Procesando respuesta para SQL...');
            
            let finalMessage = fullResponse;
            
            // Verificar si la IA gener√≥ SQL en la respuesta
            const sql = validarRespuestaSQL(fullResponse);
            
            if (sql) {
                console.log('‚úÖ [STREAMING] SQL encontrado, ejecutando consulta(s)...');
                try {
                    let results;
                    let allResults = [];
                    
                    // Manejar m√∫ltiples consultas SQL
                    if (Array.isArray(sql)) {
                        console.log(`üîÑ [STREAMING] Ejecutando ${sql.length} consultas SQL...`);
                        for (let i = 0; i < sql.length; i++) {
                            console.log(`üîç [STREAMING] Ejecutando consulta ${i + 1}/${sql.length}`);
                            const queryResults = await executeQuery(sql[i]);
                            allResults.push({
                                query: sql[i],
                                results: queryResults,
                                index: i + 1
                            });
                        }
                        results = allResults;
                    } else {
                        // Consulta √∫nica (compatibilidad)
                        results = await executeQuery(sql);
                    }
                    
                    if (results && (Array.isArray(results) ? results.length > 0 : results.length > 0)) {
                        // Guardar los resultados reales para contexto futuro
                        lastRealData = JSON.stringify(results);
                        
                        console.log('‚úÖ [STREAMING] SQL ejecutado exitosamente - haciendo segunda llamada para explicar datos');
                        
                        // Segunda llamada a la IA para explicar los datos reales de forma natural
                        // Segunda llamada espec√≠fica para explicar datos (SIN sqlRules)
                        console.log('üîÑ [STREAMING] Construyendo segunda llamada para explicar datos...');
                        
                        const fechaActual = new Date().toLocaleString('es-ES', { timeZone: 'Europe/Madrid', dateStyle: 'full', timeStyle: 'short' });
                        const promptGlobalConFecha = promptGlobal.replace('{{FECHA_ACTUAL}}', fechaActual);
                        
                        // ‚ö° CONSTRUIR SEGUNDA LLAMADA CON M√ÅXIMA PRIORIDAD CHATGPT
                        let promptExplicacion = `${promptGlobalConFecha}\n`;
                        promptExplicacion += `${prioridadMaximaChatGPT}\n\n`; // ‚ö° PRIORIDAD M√ÅXIMA AL INICIO
                        promptExplicacion += `${comportamientoChatGPT}\n\n`;
                        promptExplicacion += `${estiloVisualChatGPT}\n\n`;    // ‚ö° ESTILO CHATGPT ANTI-ROB√ìTICO
                        promptExplicacion += `${guiaMarkdownCompleta}\n\n`;  // ‚ö° GU√çA COMPLETA DE MARKDOWN
                        promptExplicacion += `${identidadEmpresa}\n\n`;
                        promptExplicacion += `${terminologia}\n\n`;
                        
                        // Los prompts organizados ya contienen toda la l√≥gica de formato
                        
                        // DEBUG: Mostrar el prompt completo que se est√° construyendo
                        console.log('üîç [DEBUG-PROMPT] Prompt unificado construido:');
                        console.log('üìÑ [DEBUG-PROMPT] Longitud total:', promptExplicacion.length, 'caracteres');
                        console.log('üìÑ [DEBUG-PROMPT] Contenido formatoRespuesta incluido:', formatoRespuesta ? 'S√ç' : 'NO');
                        
                        // A√±adir contexto RAG si existe (CR√çTICO para evitar alucinaciones)
                        try {
                            const contextoRAGSegunda = await ragInteligente.recuperarConocimientoRelevante(message, 'sistema');
                            if (contextoRAGSegunda) {
                                console.log('üéØ [RAG] Incluyendo contexto empresarial en segunda llamada');
                                // Usar el sistema de prompts unificado para el RAG tambi√©n
                                promptExplicacion += `\n${contextoRAGSegunda}\n\n`;
                            }
                        } catch (error) {
                            console.log('‚ö†Ô∏è [RAG] No se pudo obtener contexto RAG para segunda llamada:', error.message);
                        }
                        
                        // A√±adir contexto de datos previos
                        promptExplicacion += `DATOS DE CONTEXTO PREVIO:\n${JSON.stringify(results)}\n\n`;
                        
                        // A√±adir contexto conversacional
                        if (historialConversacion && historialConversacion.length > 0) {
                            const ultimosMensajes = historialConversacion.slice(-4);
                            const contextoConversacional = ultimosMensajes.map(msg => 
                                `${msg.role === 'user' ? 'Usuario' : 'Asistente'}: ${msg.content}`
                            ).join('\n');
                            
                            // Agregar contexto conversacional (SIN duplicar formatoRespuesta que ya est√° incluido)
                            console.log('üîç [DEBUG] formatoRespuesta ya incluido en l√≠nea 1042:', formatoRespuesta ? 'S√ç' : 'NO');
                            promptExplicacion += `CONTEXTO CONVERSACIONAL RECIENTE:\n\n${contextoConversacional}\n\nINSTRUCCIONES DE CONTINUIDAD:\nMant√©n la continuidad natural de la conversaci√≥n. NO te presentes de nuevo si ya has saludado. Usa el contexto previo para dar respuestas coherentes. Si el usuario hace referencia a algo mencionado antes, √∫salo. Mant√©n el tono y estilo de la conversaci√≥n en curso.\n\n`;
                        }
                        
                        promptExplicacion += `## üìä DATOS A EXPLICAR:

CONSULTA ORIGINAL: "${message}"  
${Array.isArray(sql) ? 
    `CONSULTAS SQL EJECUTADAS: ${sql.length} consultas\n${sql.map((q, i) => `${i + 1}. ${q}`).join('\n')}` : 
    `SQL EJECUTADO: ${sql}`}  
RESULTADOS: ${JSON.stringify(results, null, 2)}

## üéØ INSTRUCCI√ìN ESPEC√çFICA:

Tu tarea es explicar estos resultados de forma natural y conversacional. NO generes nuevo SQL, solo explica los datos que ya est√°n disponibles.

${Array.isArray(results) ? 
    `**IMPORTANTE**: Tienes ${results.length} conjuntos de resultados diferentes. Explica cada uno por separado usando encabezados claros.` : 
    ''}

**IMPORTANTE**: Sigue las reglas de formato visual definidas en el prompt para dar respuestas est√©ticas y bien estructuradas.


`;

                        // Segunda llamada con historial para mantener contexto
                        const mensajesSegundaLlamada = [
                            {
                                role: 'system',
                                content: promptExplicacion
                            }
                        ];

                        // Agregar historial conversacional a la segunda llamada tambi√©n
                        if (historialConversacion && historialConversacion.length > 0) {
                            historialConversacion.forEach((msg) => {
                                mensajesSegundaLlamada.push({
                                    role: msg.role,
                                    content: msg.content
                                });
                            });
                        }

                        const segundaLlamada = await openai.chat.completions.create({
                            model: 'gpt-4o',
                            messages: mensajesSegundaLlamada,
                            max_tokens: 2000,               // ‚ö° M√ÅS TOKENS PARA RESPUESTAS COMPLETAS
                            temperature: 0.9,               // ‚ö° M√ÅXIMA CREATIVIDAD
                            top_p: 0.95,                    // ‚ö° SAMPLING CREATIVO
                            frequency_penalty: 0.6,         // ‚ö° PENALIZAR FUERTEMENTE REPETICIONES
                            presence_penalty: 0.4           // ‚ö° M√ÅXIMA DIVERSIDAD EN ESTILO
                        });

                        const explicacionNatural = segundaLlamada.choices[0].message.content;
                        
                        // Reemplazar la respuesta t√©cnica con la explicaci√≥n natural
                        finalMessage = explicacionNatural;
                        
                        console.log('‚úÖ [STREAMING] Segunda llamada completada - respuesta natural generada');
                    } else {
                        // Si no hay resultados, mantener la respuesta original del modelo
                        console.log('üìö [STREAMING] Sin resultados SQL - usar respuesta del modelo');
                    }
                } catch (error) {
                    console.error('‚ùå [STREAMING-SQL] Error ejecutando consulta:', error.message);
                    // Mantener la respuesta original del modelo si hay error
                    console.log('üìö [STREAMING] Error en SQL - usar respuesta del modelo');
                }
            } else {
                console.log('üìö [STREAMING] Sin SQL - usar respuesta del modelo tal como est√°');
            }

            // Personalizar respuesta con nombre del usuario
            const respuestaPersonalizada = personalizarRespuesta(finalMessage, infoUsuario.nombre);

            // Enviar se√±al de finalizaci√≥n con conversationId
            response.write(JSON.stringify({
                type: 'end',
                fullResponse: respuestaPersonalizada,
                conversationId: conversationId,
                tokenCount: tokenCount,
                timestamp: Date.now()
            }) + '\n');

            response.end();

            // =====================================
            // POST-PROCESAMIENTO (ASYNC)
            // =====================================

            // Guardar respuesta completa en el historial de chat
            if (conversationId) {
                chatManager.addMessageToConversation(userId, conversationId, {
                    role: 'assistant',
                    content: respuestaPersonalizada
                }).catch(err =>
                    console.error('‚ùå [CHAT-HISTORY] Error guardando respuesta:', err.message)
                );
            }

            // Guardar respuesta completa en Firestore (async)
            saveAssistantMessageToFirestore(userId, respuestaPersonalizada).catch(err =>
                console.error('‚ùå [FIRESTORE] Error guardando respuesta:', err.message)
            );

            // Guardar en memoria solo si es importante (async)
            if (respuestaPersonalizada.length > 400 || message.includes('importante') || message.includes('recuerda')) {
                try {
                    pineconeMemoria.guardarAutomatico(userId, message, respuestaPersonalizada).catch(err =>
                        console.error('‚ùå [PINECONE] Error guardando en memoria:', err.message)
                    );
                } catch (error) {
                    console.error('‚ùå [PINECONE] Error guardando en memoria:', error.message);
                }
            }

            const tiempoTotal = Date.now() - tiempoInicio;
            console.log('üìä [STREAMING] Tiempo total:', tiempoTotal, 'ms');
            console.log('üìä [STREAMING] Tokens generados:', tokenCount);
            console.log('üìä [STREAMING] Respuesta completa enviada exitosamente');
            console.log('üîÑ [STREAMING] Conversaci√≥n guardada en historial:', conversationId);

            return { success: true, streamed: true, conversationId };

        } catch (streamError) {
            console.error('‚ùå [STREAMING] Error en stream:', streamError);
            
            // Enviar error al frontend
            response.write(JSON.stringify({
                type: 'error',
                message: 'Error en el streaming',
                timestamp: Date.now()
            }) + '\n');
            
            response.end();
            return { success: false, error: streamError.message };
        }

    } catch (error) {
        console.error('‚ùå [STREAMING] Error cr√≠tico:', error);
        
        if (!response.headersSent) {
            response.writeHead(500, { 'Content-Type': 'application/json' });
            response.end(JSON.stringify({ 
                success: false, 
                error: 'Error interno del servidor' 
            }));
        }
        
        return { success: false, error: error.message };
    }
}

// =====================================
// M√ìDULO DE EXPORTACI√ìN
// =====================================
// 
// Este m√≥dulo exporta la funci√≥n principal:
// - processQueryStream: Procesamiento con streaming en tiempo real
// 
// USO EN OTROS ARCHIVOS:
// const { processQueryStream } = require('./admin/core/openAI');
// =====================================

/**
 * Exportar la funci√≥n principal para su uso en otros archivos
 */
module.exports = {
    processQueryStream
};

/**
 * Construye el contexto del mapa ERP COMPLETO para que la IA analice
 */
function construirContextoMapaERPCompleto(mapaERP) {
    if (!mapaERP) {
        console.log('‚ö†Ô∏è [MAPA-ERP] No hay mapaERP disponible');
        return '';
    }
    

    
    let contexto = '\n=== ESTRUCTURA COMPLETA DE LA BASE DE DATOS ===\n';
    contexto += `\nTOTAL DE TABLAS DISPONIBLES: ${Object.keys(mapaERP).length}\n\n`;
    
    // Incluir TODAS las tablas del mapaERP para que la IA las analice
    Object.entries(mapaERP).forEach(([nombreTabla, infoTabla]) => {
        contexto += `\n## üìä TABLA: ${nombreTabla}\n`;
        contexto += `Descripci√≥n: ${infoTabla.descripcion || 'Sin descripci√≥n'}\n`;
        
        // Columnas disponibles
        if (infoTabla.columnas) {
            contexto += `\n### üìã COLUMNAS:\n`;
            Object.entries(infoTabla.columnas).forEach(([columna, descripcion]) => {
                contexto += `- ${columna}: ${descripcion}\n`;
            });
        }
        
        // Relaciones con otras tablas
        if (infoTabla.tablas_relacionadas) {
            contexto += `\n### üîó RELACIONES:\n`;
            Object.entries(infoTabla.tablas_relacionadas).forEach(([tablaRelacionada, infoRelacion]) => {
                contexto += `- ${tablaRelacionada}: ${infoRelacion.descripcion || 'Relaci√≥n directa'}\n`;
                if (infoRelacion.tipo) {
                    contexto += `  Tipo: ${infoRelacion.tipo}\n`;
                }
                if (infoRelacion.campo_enlace_local && infoRelacion.campo_enlace_externo) {
                    contexto += `  JOIN: ${nombreTabla}.${infoRelacion.campo_enlace_local} = ${tablaRelacionada}.${infoRelacion.campo_enlace_externo}\n`;
                }
            });
        }
        
        contexto += '\n';
    });
    
    // Instrucciones para la IA
    contexto += `\n### üéØ INSTRUCCIONES PARA LA IA:\n`;
    contexto += `- Analiza la consulta del usuario\n`;
    contexto += `- Identifica qu√© tablas del mapaERP son relevantes\n`;
    contexto += `- Usa las relaciones definidas para hacer JOINs correctos\n`;
    contexto += `- NO inventes tablas que no est√©n en esta lista\n`;
    contexto += `- Genera SQL usando EXACTAMENTE las columnas mostradas\n`;
    contexto += `- Formato: <sql>SELECT columnas FROM tabla [JOIN otras_tablas] WHERE condiciones</sql>\n\n`;
    

    return contexto;
}

/**
 * Selecciona el modelo apropiado para la consulta
 */
function seleccionarModeloInteligente(intencion, tablasRelevantes) {
    // ‚úÖ CONFIGURACI√ìN ULTRA-NATURAL COMO CHATGPT
    const config = {
        modelo: 'gpt-4o',           // Modelo m√°s capaz para naturalidad
        maxTokens: 3000,            // Tokens generosos para variabilidad
        temperature: 0.9,           // ‚ö° M√ÅXIMA CREATIVIDAD Y VARIABILIDAD
        topP: 0.95,                 // Sampling creativo
        frequencyPenalty: 0.5,      // ‚ö° PENALIZAR FUERTEMENTE REPETICIONES
        presencePenalty: 0.4,       // ‚ö° M√ÅXIMA DIVERSIDAD EN TEMAS Y ESTILO
        razon: 'Configuraci√≥n ultra-natural para eliminar rob√≥tica y repetitividad'
    };
    
    return config;
}

/**
 * Construye las instrucciones naturales para el prompt
 */
function construirInstruccionesNaturales(intencion, tablasRelevantes, contextoPinecone) {
    // ‚ö° PRIORIDAD M√ÅXIMA AL INICIO - ESTILO CHATGPT
    let instrucciones = prioridadMaximaChatGPT + '\n\n';  // ‚ö° PRIORIDAD M√ÅXIMA
    instrucciones += comportamientoChatGPT + '\n\n';
    instrucciones += estiloVisualChatGPT + '\n\n';       // ‚ö° ESTILO VISUAL CHATGPT ANTI-ROB√ìTICO
    instrucciones += guiaMarkdownCompleta + '\n\n';     // ‚ö° GU√çA COMPLETA DE MARKDOWN
    instrucciones += identidadEmpresa + '\n\n';
    instrucciones += terminologia + '\n\n';
    
    // Los prompts organizados ya contienen toda la l√≥gica necesaria
    
    return instrucciones;
}

/**
 * Genera embeddings para an√°lisis sem√°ntico
 */
async function generarEmbedding(texto) {
    try {
        const response = await openai.embeddings.create({
            model: 'text-embedding-3-small',
            input: texto
        });
        return response.data[0].embedding;
    } catch (error) {
        console.error('‚ùå [EMBEDDING] Error generando embedding:', error.message);
        return null;
    }
}

// =====================================
// EXPORTACIONES DEL M√ìDULO
// =====================================

module.exports = {
    // Funci√≥n principal de consulta
    consultaModelo,
    
    // Funciones auxiliares
    analizarIntencionInteligente,
    construirPromptUnificado,
    seleccionarModeloInteligente,
    construirInstruccionesNaturales,
    generarEmbedding
};