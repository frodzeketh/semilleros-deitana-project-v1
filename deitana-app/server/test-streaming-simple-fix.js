// =====================================
// TEST SIMPLE DE STREAMING - VERSI√ìN B√ÅSICA
// =====================================

const { OpenAI } = require('openai');
require('dotenv').config();

const openai = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY
});

async function testStreamingSimple() {
    console.log('üß™ [TEST] Iniciando test de streaming simple...');
    
    // Simular respuesta HTTP
    let chunksRecibidos = [];
    let finalResponse = '';
    
    const mockResponse = {
        writeHead: (status, headers) => {
            console.log('üì§ [MOCK] Headers enviados:', status);
        },
        write: (data) => {
            console.log('üì§ [MOCK] Chunk recibido:', data.toString().substring(0, 100));
            chunksRecibidos.push(data.toString());
            
            // Parsear el JSON
            try {
                const lines = data.toString().split('\n').filter(line => line.trim());
                for (const line of lines) {
                    const parsed = JSON.parse(line);
                    if (parsed.type === 'chunk' && parsed.content) {
                        finalResponse += parsed.content;
                    }
                }
            } catch (error) {
                console.log('‚ö†Ô∏è [MOCK] Error parseando:', error.message);
            }
        },
        end: () => {
            console.log('üèÅ [MOCK] Response finalizada');
        }
    };
    
    try {
        console.log('üöÄ [TEST] Llamando a OpenAI...');
        
        const stream = await openai.chat.completions.create({
            model: 'gpt-4o',
            messages: [
                {
                    role: 'system',
                    content: 'Eres un asistente √∫til. Responde de forma natural y amigable.'
                },
                {
                    role: 'user',
                    content: 'hola'
                }
            ],
            max_tokens: 100,
            temperature: 0.3,
            stream: true
        });

        console.log('‚úÖ [TEST] Stream iniciado correctamente');

        // Procesar cada chunk del stream
        for await (const chunk of stream) {
            const content = chunk.choices[0]?.delta?.content;
            
            if (content) {
                // Enviar chunk al frontend
                mockResponse.write(JSON.stringify({
                    type: 'chunk',
                    content: content,
                    timestamp: Date.now()
                }) + '\n');
            }
            
            // Si el stream termin√≥
            if (chunk.choices[0]?.finish_reason) {
                console.log('‚úÖ [TEST] Stream completado');
                break;
            }
        }

        // Enviar se√±al de finalizaci√≥n
        mockResponse.write(JSON.stringify({
            type: 'end',
            fullResponse: finalResponse,
            timestamp: Date.now()
        }) + '\n');

        mockResponse.end();
        
        console.log('‚úÖ [TEST] Test completado exitosamente');
        console.log('üìä [TEST] Chunks recibidos:', chunksRecibidos.length);
        console.log('üìù [TEST] Respuesta final:', finalResponse);
        
    } catch (error) {
        console.error('‚ùå [TEST] Error en test:', error);
    }
}

// Ejecutar test
testStreamingSimple(); 